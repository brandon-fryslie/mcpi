# SPRINT 1: Foundation Repair - Test Infrastructure Recovery

**Sprint Goal**: Fix critical test infrastructure issues to enable validation and feature development
**Duration**: 3-4 days
**Status**: Not Started
**Based On**: PLAN-2025-10-21-225314.md Phase 1
**Source Assessment**: STATUS-2025-10-21-225033.md

---

## Sprint Overview

This sprint focuses exclusively on **Phase 1 (Foundation Repair)** from the main plan. The goal is to stabilize the test infrastructure and implement missing APIs required for the rescope feature.

**Why This Sprint Is Critical**:
- Cannot implement rescope feature without stable foundation
- Cannot validate any implementation without working tests
- Current state: 31% of test suite broken (19 import errors)
- Missing critical API method required for rescope

**Sprint Success Criteria**:
- [ ] All test files can import (0 import errors, down from 19)
- [ ] `ScopeHandler.get_server_config()` method implemented and tested
- [ ] Core functionality validated with working tests
- [ ] Technical debt reduced to manageable level

---

## Day 1: Test Import Triage and API Implementation

### Morning: Categorize Broken Tests (4 hours)

**Task**: Analyze all 19 broken test files and categorize them

**Work Items**:
1. Run `pytest tests/ --collect-only` to get full list of import errors
2. For each broken test file, determine:
   - Is the test obsolete? (tests deleted functionality) → DELETE
   - Is the test outdated? (tests existing functionality but API changed) → UPDATE
   - Is the test valid? (tests functionality that should exist) → FIX or IMPLEMENT

3. Create categorization spreadsheet:
   ```
   | Test File | Error | Category | Action | Priority |
   |-----------|-------|----------|--------|----------|
   | test_registry_manager.py | No module 'registry.manager' | Obsolete? | Investigate | P0 |
   | test_installer_claude_code.py | No 'ServerInstallation' | Outdated | Update imports | P0 |
   ...
   ```

**Deliverable**: Categorization document showing which tests to delete, update, or fix

**Success Metric**: Clear action plan for all 19 broken tests

---

### Afternoon: Implement get_server_config() API (4 hours)

**Task**: Add missing `ScopeHandler.get_server_config()` method (P0-2)

**Work Items**:
1. Open `/Users/bmf/icode/mcpi/src/mcpi/clients/base.py`
2. Review existing `ScopeHandler` abstract base class methods
3. Add abstract method signature:
   ```python
   @abstractmethod
   def get_server_config(self, server_id: str) -> ServerConfig:
       """Returns the full configuration for a specific server.

       Args:
           server_id: The ID of the server to retrieve

       Returns:
           ServerConfig object with full server configuration

       Raises:
           ServerNotFoundError: If server doesn't exist in this scope
       """
       pass
   ```

4. Implement method in `FileBasedScope` class:
   ```python
   def get_server_config(self, server_id: str) -> ServerConfig:
       """Implementation for file-based scope handler."""
       if not self.has_server(server_id):
           raise ServerNotFoundError(f"Server '{server_id}' not found in scope '{self.scope_id}'")

       # Read server config from scope file
       # (implementation depends on current file structure)
       ...
   ```

5. Write basic unit tests in new file `tests/test_scope_handler.py`:
   - Test success path: server exists → returns config
   - Test error path: server doesn't exist → raises error
   - Test data integrity: returned config matches file content

**Deliverable**: Working `get_server_config()` method with tests

**Success Metric**: Method exists, returns correct data, raises appropriate errors

**Files Modified**:
- `/Users/bmf/icode/mcpi/src/mcpi/clients/base.py`
- `/Users/bmf/icode/mcpi/tests/test_scope_handler.py` (new)

---

## Day 2: Fix High-Priority Test Imports

### Morning: Fix Installer Test Imports (4 hours)

**Task**: Fix import errors in installer tests (6 files)

**Broken Files** (from STATUS):
- `tests/test_installer_claude_code.py`
- `tests/test_installer_npm.py`
- `tests/test_installer_python.py`
- `tests/test_installer_git.py`
- `tests/functional/test_installation_workflows.py`

**Common Issue**: Cannot import `ServerInstallation` class

**Work Items**:
1. Search codebase for what replaced `ServerInstallation`:
   ```bash
   grep -r "class ServerInstallation" src/
   grep -r "ServerConfig" src/
   grep -r "ServerState" src/
   ```

2. For each test file:
   - Update import statements to current API
   - Update test mocks/fixtures to match current data models
   - Run individual test: `pytest tests/test_installer_X.py -v`
   - Fix any assertion errors due to API changes

3. If `ServerInstallation` was completely removed:
   - Determine if tests should use `ServerConfig` instead
   - Update all references throughout test files

**Deliverable**: All 6 installer test files can import and execute

**Success Metric**: `pytest tests/test_installer_*.py --collect-only` succeeds

**Files Modified**:
- `tests/test_installer_claude_code.py`
- `tests/test_installer_npm.py`
- `tests/test_installer_python.py`
- `tests/test_installer_git.py`
- `tests/functional/test_installation_workflows.py`

---

### Afternoon: Fix Registry Test Imports (4 hours)

**Task**: Fix import errors in registry tests (4 files)

**Broken Files** (from STATUS):
- `tests/test_registry.py`
- `tests/test_registry_manager.py`
- `tests/functional/test_end_to_end_workflows.py`
- `tests/test_discovery.py`

**Common Issue**: Missing `mcpi.registry.manager` and `mcpi.registry.doc_parser` modules

**Work Items**:
1. Determine why modules were deleted:
   ```bash
   git log --all --full-history -- src/mcpi/registry/manager.py
   git log --all --full-history -- src/mcpi/registry/doc_parser.py
   ```

2. Check if functionality still exists elsewhere:
   ```bash
   grep -r "class RegistryManager" src/
   grep -r "class DocParser" src/
   ```

3. For each test file, determine:
   - **If functionality deleted**: Delete obsolete tests
   - **If functionality moved**: Update imports to new location
   - **If functionality should exist**: Create issue to reimplement, skip tests for now

4. Focus on `test_registry.py` and `test_discovery.py` first (likely still relevant)
5. Defer `test_registry_manager.py` if module truly obsolete

**Deliverable**: Registry tests either working or marked as skip with clear reason

**Success Metric**: `pytest tests/test_registry.py tests/test_discovery.py` executes

**Files Modified**:
- `tests/test_registry.py`
- `tests/test_registry_manager.py` (may delete if obsolete)
- `tests/functional/test_end_to_end_workflows.py`
- `tests/test_discovery.py`

---

## Day 3: Fix Remaining Tests and Technical Debt

### Morning: Fix CLI and Config Test Imports (4 hours)

**Task**: Fix remaining test import errors (9 files)

**Broken Files** (from STATUS):
- `tests/test_cli_comprehensive.py` (missing `get_method_string`)
- `tests/test_config_manager.py`
- `tests/test_config_profiles.py`
- `tests/test_config_templates.py`
- `tests/test_validation.py`
- `tests/test_cli_config.py`
- `tests/test_cli_install.py`
- `tests/test_cli_search.py`
- `tests/test_cli_status.py`
- `tests/test_plugin_system.py`

**Work Items**:
1. Group files by issue type:
   - CLI tests with missing functions → find current API
   - Config tests with missing imports → update imports
   - Plugin system tests → verify against current architecture

2. For CLI tests:
   - Search for `get_method_string` replacement:
     ```bash
     grep -r "def get_method_string" src/
     ```
   - If deleted, determine what replaced it or remove calls

3. For config tests:
   - Verify config modules still exist in `src/mcpi/config/`
   - Update imports to match current structure

4. For plugin tests:
   - Verify against current plugin architecture in `src/mcpi/clients/`
   - Update mocks to match current `MCPManager` API

**Deliverable**: All remaining test files can import

**Success Metric**: `pytest tests/ --collect-only` succeeds with 0 import errors

**Files Modified**: All 9 remaining broken test files

---

### Afternoon: Critical Technical Debt Cleanup (4 hours)

**Task**: Clean high-impact technical debt (P0-3)

**Work Items**:
1. Search for broken references to deleted modules:
   ```bash
   grep -r "ClaudeCodeInstaller" src/ tests/ | wc -l
   grep -r "registry.manager" src/ tests/ | wc -l
   grep -r "registry.doc_parser" src/ tests/ | wc -l
   grep -r "ServerInstallation" src/ tests/ | wc -l
   ```

2. Categorize by severity:
   - **P0 (blocking)**: Import statements in active code → FIX NOW
   - **P1 (important)**: Type hints in active code → FIX NOW
   - **P2 (cosmetic)**: Comments mentioning old modules → DEFER

3. For blocking issues:
   - Update imports to current API
   - Update type hints to current models
   - Run linter to verify: `ruff check src/ tests/`

4. For cosmetic issues:
   - Create list for future cleanup
   - Don't spend time on comments/docs today

**Deliverable**: All blocking technical debt cleaned (imports, type hints)

**Success Metric**: `ruff check src/ tests/` passes without errors for deleted modules

**Target**: Reduce 171+ broken references to <50 (focus on blocking issues)

---

## Day 4: Validation and Sprint Completion

### Morning: Core Functionality Validation (4 hours)

**Task**: Validate core functionality with working test suite (P0-4)

**Work Items**:
1. Run full test suite:
   ```bash
   pytest tests/ -v
   ```

2. Review results:
   - Count passing tests
   - Count failing tests (may fail assertions, but should execute)
   - Count skipped tests (marked as skip intentionally)

3. For core CLI commands, verify test coverage:
   ```bash
   pytest --cov=src/mcpi/cli --cov-report=html tests/test_cli*.py
   ```

4. Manual smoke tests for commands that work (from STATUS):
   ```bash
   python -m mcpi.cli list
   python -m mcpi.cli client list
   python -m mcpi.cli scope list
   python -m mcpi.cli registry list
   python -m mcpi.cli info <server-name>
   python -m mcpi.cli status
   ```

5. Compare test coverage report against STATUS claims:
   - Previous report claimed various coverage percentages
   - Measure actual coverage now that tests run
   - Document gaps between claimed and actual coverage

**Deliverable**: Test suite status report with actual coverage numbers

**Success Metric**: >80% of tests can execute (may not all pass, but run)

---

### Afternoon: Sprint Retrospective and Phase 2 Prep (4 hours)

**Task**: Review sprint completion and prepare for Phase 2

**Work Items**:
1. **Sprint Review**:
   - Compare actual vs. planned work completed
   - Document any surprises or discoveries
   - Update PLAN if major changes needed

2. **Verify Phase 1 Completion Criteria**:
   - [ ] All test files can import (0 import errors)
   - [ ] `ScopeHandler.get_server_config()` implemented and tested
   - [ ] Core functionality validated with working tests
   - [ ] Critical technical debt cleaned

3. **Phase 2 Readiness Check**:
   - Can we safely implement rescope feature?
   - Are all prerequisites met?
   - Any remaining blockers?

4. **Create Phase 2 TODO**:
   - If Phase 1 complete: Create detailed Phase 2 TODO list
   - If Phase 1 incomplete: Identify what needs carryover

5. **Update STATUS File**:
   - Create new STATUS-YYYY-MM-DD-HHMMSS.md with current state
   - Document progress from 40% → estimated new completion %
   - Note any architectural discoveries

**Deliverable**:
- Sprint retrospective document
- Updated STATUS file
- Phase 2 readiness assessment

**Success Metric**: Clear GO/NO-GO decision for Phase 2 implementation

---

## Sprint Metrics and Success Criteria

### Quantitative Metrics

**Test Health**:
- Starting: 19 import errors (31% of test suite broken)
- Target: 0 import errors (100% of test suite can collect)
- Stretch: >80% of tests execute and pass

**API Completeness**:
- Starting: Missing `get_server_config()` method (rescope blocker)
- Target: Method implemented with >90% coverage
- Stretch: Method fully integrated and documented

**Technical Debt**:
- Starting: 171+ broken references to deleted modules
- Target: <50 broken references (blocking issues resolved)
- Stretch: <10 broken references (cosmetic issues cleaned)

**Coverage Accuracy**:
- Starting: Unverifiable (tests don't run)
- Target: Accurate measurement of actual coverage
- Stretch: >70% coverage of core modules

---

### Qualitative Metrics

**Code Quality**:
- Starting: "Somewhat broken but somewhat working" (actual commit message)
- Target: "Tests run, core functionality validated"
- Stretch: "Production-ready foundation"

**Developer Confidence**:
- Starting: Cannot trust test results or coverage claims
- Target: Can run tests and trust results
- Stretch: Can confidently implement new features

**Navigability**:
- Starting: Hard to distinguish active code from legacy code
- Target: Clear which code is active vs. deprecated
- Stretch: Easy to onboard new developers

---

## Daily Standups (Self-Check)

### Daily Questions
1. What did I complete yesterday?
2. What am I working on today?
3. What blockers or surprises did I encounter?
4. Am I on track for sprint completion?

### Day 1 Standup
- **Goal**: Categorize tests, implement `get_server_config()`
- **Blocker Check**: Are test categories clear? Is API design sound?

### Day 2 Standup
- **Goal**: Fix installer and registry test imports
- **Blocker Check**: Are API replacements clear? Any missing modules?

### Day 3 Standup
- **Goal**: Fix remaining tests, clean critical debt
- **Blocker Check**: Are there unexpected architectural issues?

### Day 4 Standup
- **Goal**: Validate functionality, complete sprint
- **Blocker Check**: Are Phase 1 criteria met? Ready for Phase 2?

---

## Risk Management

### High-Risk Items
1. **Test obsolescence > 50%**: If most tests are obsolete, delete them
   - Mitigation: Focus on new tests for rescope feature instead
   - Contingency: Day 1 categorization will reveal this early

2. **API replacement unclear**: If `ServerInstallation` replacement not obvious
   - Mitigation: Review git history, check recent refactors
   - Contingency: Ask user for guidance on architectural intent

### Medium-Risk Items
1. **Technical debt deeper than expected**: If 171+ references are complex
   - Mitigation: Focus on blocking issues, defer cosmetic cleanup
   - Contingency: Extend cleanup to post-sprint work

2. **Core functionality broken**: If manual tests reveal issues
   - Mitigation: Fix critical issues, document non-critical issues
   - Contingency: May delay Phase 2 start

### Low-Risk Items
1. **Documentation gaps**: Found during validation
   - Mitigation: Note for later, don't block sprint
   - Contingency: Add to Phase 2 documentation task

---

## Definition of Done

### Sprint Complete When:
- [ ] All 19 test import errors resolved
- [ ] `pytest tests/ --collect-only` succeeds
- [ ] `ScopeHandler.get_server_config()` method exists, tested, working
- [ ] Full test suite can execute (>80% of tests run)
- [ ] Critical technical debt cleaned (blocking imports/type hints)
- [ ] Core functionality validated (manual + automated tests)
- [ ] Sprint retrospective completed
- [ ] Phase 2 readiness assessed (GO/NO-GO decision)

### Ready for Phase 2 When:
- [ ] All Phase 1 success criteria met (from PLAN-2025-10-21-225314.md)
- [ ] No import errors in test suite
- [ ] Required API methods implemented and tested
- [ ] Core modules validated with working tests
- [ ] Team confidence: "Foundation is stable"

---

## Files to Modify (Reference)

### Will Modify:
- `/Users/bmf/icode/mcpi/src/mcpi/clients/base.py` - Add get_server_config()
- `/Users/bmf/icode/mcpi/tests/test_scope_handler.py` - New tests for API
- 19 broken test files (see Day 1-3 tasks for list)
- Various files with broken imports (identified during Day 3)

### Will Review:
- `/Users/bmf/icode/mcpi/src/mcpi/registry/` - Understand current structure
- `/Users/bmf/icode/mcpi/src/mcpi/installer/` - Understand current API
- `/Users/bmf/icode/mcpi/src/mcpi/clients/` - Understand plugin architecture
- `/Users/bmf/icode/mcpi/src/mcpi/config/` - Understand config structure

### Will Reference:
- `/Users/bmf/icode/mcpi/STATUS-2025-10-21-225033.md` - Current state
- `/Users/bmf/icode/mcpi/PLAN-2025-10-21-225314.md` - Overall plan
- `/Users/bmf/icode/mcpi/.agent_planning/BACKLOG.md` - Rescope spec
- `/Users/bmf/icode/mcpi/CLAUDE.md` - Architecture guide

---

## Next Sprint Preview: Phase 2 - Rescope Implementation

**Sprint 2 Goals** (after Sprint 1 complete):
- Implement core rescope logic with rollback
- Add CLI `rescope` command
- Write comprehensive tests (95%+ coverage)
- Document feature in README and CHANGELOG

**Sprint 2 Duration**: 2-3 days

**Sprint 2 Prerequisites**: All Sprint 1 success criteria met

---

**END OF SPRINT 1 PLAN**

**Ready to Start**: After review and approval of this plan
**Daily Progress**: Update this file with actual progress vs. planned
**Completion**: Review against Definition of Done before moving to Phase 2
