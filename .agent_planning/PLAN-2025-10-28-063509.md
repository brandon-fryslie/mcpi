# MCPI Implementation Plan: Test Infrastructure Repair and Core Functionality Completion

**Source**: STATUS-2025-10-28-063053.md (68% completion, test infrastructure broken)
**Spec Version**: PROJECT_SPEC.md, CLAUDE.md (plugin-based scope architecture)
**Generated**: 2025-10-28 06:35:09

---

## Executive Summary

The MCPI project has **68% functional completion** with a solid plugin-based architecture and working core features (list, search, rescope, completion). However, the project suffers from **critical test infrastructure decay** that blocks validation and production deployment:

**Critical Findings from STATUS**:
- **19 of 60 test files fail at import** (31% of test suite broken)
- **Core functionality WORKS** (list, search, info, rescope, completion)
- **Installation system UNCERTAIN** (tests fail, unclear if functional)
- **Documentation MISLEADING** (describes non-existent features)
- **Dead code present** (75KB of legacy files)
- **Architecture evolved beyond spec** (scope-based > profile-based)

**Strategic Priorities**:
1. **P0: Repair test infrastructure** - Cannot validate functionality with 31% of tests broken
2. **P1: Verify/fix installation system** - Core purpose of tool, tests failing
3. **P1: Align documentation** - README describes features that don't exist
4. **P2: Implement missing core features** - Complete the MVP (update, categories, status)
5. **P3: Clean technical debt** - Dead code and architectural alignment

**Total Work Items**: 16 prioritized tasks
**Estimated Timeline**: 3-4 weeks to production-ready 1.0
**Immediate Focus**: Fix test infrastructure (Week 1)

---

## Prioritized Backlog

### P0: BLOCKING (Must Fix Immediately)

These items block all validation work and prevent confident releases.

---

## P0-1: Fix Broken Test Import Errors (19 files)

**Status**: Not Started
**Effort**: Medium (3-5 days)
**Dependencies**: None
**Spec Reference**: CLAUDE.md Testing Strategy • **Status Reference**: STATUS-2025-10-28-063053.md lines 145-176, 323-342

### Description

31% of the test suite (19 of 60 files) cannot import due to references to deleted modules. This is the **PRIMARY BLOCKER** - we cannot validate any functionality with broken tests.

**Deleted Modules Causing Failures**:
- `mcpi.registry.manager` → 3 files fail
- `ServerInstallation` class → 11 files fail
- `get_method_string` function → 3 files fail
- `mcpi.registry.doc_parser` → 2 files fail
- `Platform` enum → 1 file fails
- `ServerVersions` class → 1 file fails

**Evidence**: STATUS lines 169-174 show exact import error patterns.

### Acceptance Criteria

- [ ] All 19 test files can import successfully (0 import errors on `pytest --collect-only`)
- [ ] Categorize each broken test: DELETE (obsolete) vs UPDATE (still relevant)
- [ ] For UPDATE category: align imports with current API
- [ ] For DELETE category: remove obsolete test files
- [ ] Document what replaced deleted modules (migration guide)
- [ ] At least 80% of tests execute (may fail assertions, but must run)
- [ ] Update conftest.py fixtures to match current data models

### Technical Notes

**Strategy**:
1. Run `pytest --collect-only` to get full list of import errors
2. For each error, search codebase: `grep -r "deleted_module" src/`
3. Determine if functionality still exists under different API
4. Three categories:
   - **Obsolete functionality** → DELETE test file
   - **Renamed/moved functionality** → UPDATE imports
   - **Missing functionality** → Flag as gap (separate work item)

**Likely Findings**:
- `ServerInstallation`: Replaced by `ServerInfo` or `ServerConfig` types in `clients/types.py`
- `registry.manager`: Functionality merged into `clients/manager.py`
- `registry.doc_parser`: Feature removed, tests obsolete
- `get_method_string`: Likely replaced by `ServerInfo.command` or similar

**Files to Review for Current API**:
- `/Users/bmf/Library/Mobile Documents/com~apple~CloudDocs/_mine/icode/mcpi/src/mcpi/clients/types.py`
- `/Users/bmf/Library/Mobile Documents/com~apple~CloudDocs/_mine/icode/mcpi/src/mcpi/clients/manager.py`
- `/Users/bmf/Library/Mobile Documents/com~apple~CloudDocs/_mine/icode/mcpi/src/mcpi/registry/catalog.py`

---

## P0-2: Remove Dead Code Files

**Status**: Not Started
**Effort**: Small (1-2 days)
**Dependencies**: None
**Spec Reference**: N/A (cleanup) • **Status Reference**: STATUS-2025-10-28-063053.md lines 136-142

### Description

Three legacy CLI files waste 75KB and create navigation confusion:
- `cli_old.py` (41KB)
- `cli_optimized.py` (8.6KB)
- `cli_original.py` (25KB)

These files are deprecated/superseded and should be deleted immediately.

### Acceptance Criteria

- [ ] Delete `src/mcpi/cli_old.py`
- [ ] Delete `src/mcpi/cli_optimized.py`
- [ ] Delete `src/mcpi/cli_original.py`
- [ ] Search for any imports of deleted files: `grep -r "cli_old\|cli_optimized\|cli_original" src/ tests/`
- [ ] Remove any imports found (should be none if truly dead)
- [ ] Verify `mcpi` command still works: `python -m mcpi.cli --help`
- [ ] Run test suite to ensure nothing broke

### Technical Notes

**Quick Win**: This is a 30-minute task that immediately improves codebase quality.

**Validation**:
```bash
# Before deletion
ls -lh src/mcpi/cli*.py

# After deletion (should only see cli.py)
ls -lh src/mcpi/cli*.py

# Verify no references
git grep -n "cli_old\|cli_optimized\|cli_original"
```

---

## P0-3: Verify Core Functionality with Manual Testing

**Status**: Not Started
**Effort**: Small (1-2 days)
**Dependencies**: P0-1 (need some working tests)
**Spec Reference**: CLAUDE.md CLI Interface • **Status Reference**: STATUS-2025-10-28-063053.md lines 251-297

### Description

STATUS confirms basic commands work manually, but installation commands (add/remove/status) have failing tests. **Before fixing tests, verify if commands actually work** - tests may be wrong, not code.

**Known Working** (from STATUS):
- ✓ `mcpi list` - Shows 7 servers in table
- ✓ `mcpi search` - Command exists
- ✓ `mcpi info` - Command exists
- ✓ `mcpi rescope` - 27/28 tests passing
- ✓ `mcpi completion` - 69/72 tests passing
- ✓ `mcpi client list` - Shows detected clients
- ✓ `mcpi scope list` - Shows available scopes

**Uncertain** (tests fail, unclear if functional):
- ? `mcpi add <server>` - 38 test failures
- ? `mcpi remove <server>` - Tests fail
- ? `mcpi status` - Tests fail

### Acceptance Criteria

- [ ] Manually test `mcpi add` with real MCP server from registry
- [ ] Manually test `mcpi remove` with installed server
- [ ] Manually test `mcpi status` to check server states
- [ ] Document actual behavior vs test expectations
- [ ] Create GitHub issues for any broken commands found
- [ ] Update test expectations if commands work but tests wrong
- [ ] Identify if issue is in command implementation or test mocks

### Technical Notes

**Testing Procedure**:
```bash
# Test add command with real server
mcpi add filesystem --scope project-mcp

# Verify it appears in list
mcpi list --scope project-mcp

# Check config file directly
cat .mcp.json

# Test remove
mcpi remove filesystem --scope project-mcp

# Verify it's gone
mcpi list --scope project-mcp
```

**Outcome Scenarios**:
1. **Commands work** → Fix tests (they're wrong)
2. **Commands broken** → Fix implementation (tests are right)
3. **Commands partially work** → Fix both implementation and tests

---

### P1: CRITICAL (Blocks Production Use)

These items are required for MVP functionality but not immediate blockers.

---

## P1-1: Fix or Verify Installation System (add/remove commands)

**Status**: Not Started
**Effort**: Medium (3-5 days)
**Dependencies**: P0-3 (manual verification results)
**Spec Reference**: PROJECT_SPEC.md lines 145-149 • **Status Reference**: STATUS-2025-10-28-063053.md lines 60-75, 299-319

### Description

Installation commands exist but tests fail with `AttributeError` in mocks. STATUS shows:
- `test_install_command_multiple_servers` FAILED
- `test_uninstall_command` FAILED
- `test_status_command_with_servers` FAILED

Need to either:
1. Fix the tests (if commands work per P0-3)
2. Fix the implementation (if commands broken per P0-3)
3. Both (if partial functionality)

**Root Cause Investigation Required**:
- Are test mocks outdated vs actual API?
- Is validation logic in `clients/claude_code.py` broken?
- Do commands work with real servers or just test failures?

### Acceptance Criteria

- [ ] Investigate test failures: mock API mismatch vs real issue
- [ ] If tests wrong: update mocks to current API
- [ ] If implementation wrong: fix validation/installation logic
- [ ] Verify `add` command works with npm, pip, uv, git installation methods
- [ ] Verify `remove` command cleanly removes servers from config
- [ ] Verify `status` command shows accurate server states
- [ ] All installer tests pass (currently 36 failures in claude_code tests)
- [ ] Integration test: install real server, use it, remove it

### Technical Notes

**Test Failure Pattern** (from STATUS line 69-73):
```python
FAILED tests/test_cli.py::TestCLICommands::test_install_command_multiple_servers
FAILED tests/test_cli.py::TestCLICommands::test_uninstall_command
FAILED tests/test_cli.py::TestCLICommands::test_status_command_with_servers
```

**Files to Review**:
- `src/mcpi/clients/claude_code.py` (504 LOC, 36 test failures)
- `tests/test_clients_claude_code.py` (validation logic tests)
- `tests/test_cli.py` (38 failures, 89 passes)

**Success Metric**: Can install a real MCP server from registry and use it successfully.

---

## P1-2: Update README to Remove Non-Existent Features

**Status**: Not Started
**Effort**: Small (1-2 days)
**Dependencies**: P0-3, P1-1 (know what actually works)
**Spec Reference**: N/A (documentation) • **Status Reference**: STATUS-2025-10-28-063053.md lines 199-225

### Description

README is **critically misleading** - describes features that don't exist, causing poor user experience:

**Misleading Content** (from STATUS):
- Line 38: `mcpi config init` shown in Quick Start but doesn't work
- Lines 169-220: Entire config section describes non-existent profile features
- Line 245: Configuration file locations describe files that aren't used

**Missing Documentation**:
- No docs for `rescope` command (implemented, 27/28 tests passing)
- No docs for `completion` command (implemented, 69/72 tests passing)
- No explanation of scope-based architecture (actual implementation)
- No clarification of scope vs profile (confusion source)

### Acceptance Criteria

- [ ] Remove ALL references to `mcpi config init` (doesn't exist)
- [ ] Remove profile management section (lines 169-220)
- [ ] Remove misleading configuration file location section
- [ ] Add documentation for `rescope` command with examples
- [ ] Add documentation for `completion` command with examples
- [ ] Add "Scope-Based Architecture" section explaining actual design
- [ ] Update Quick Start with commands that actually work
- [ ] Add troubleshooting section for actual error patterns (not generic)
- [ ] Verify all documented commands work (manual test each one)

### Technical Notes

**Commands to Document**:
```bash
# Rescope feature (implemented, not documented)
mcpi rescope my-server --from project-mcp --to user-internal

# Completion feature (implemented, not documented)
mcpi completion install bash
mcpi completion install zsh

# Scope inspection (implemented, not documented)
mcpi scope list
mcpi scope show user-internal

# Client management (implemented, not documented)
mcpi client list
mcpi client show claude-code
```

**Documentation Principles**:
- Only document what EXISTS and WORKS
- Show real examples users can run
- Explain actual architecture (scope-based), not spec architecture (profile-based)

---

## P1-3: Update PROJECT_SPEC.md to Match Actual Implementation

**Status**: Not Started
**Effort**: Medium (3-5 days)
**Dependencies**: P0-3, P1-1 (know full current state)
**Spec Reference**: PROJECT_SPEC.md (entire document) • **Status Reference**: STATUS-2025-10-28-063053.md lines 346-365

### Description

PROJECT_SPEC.md describes a **profile-based architecture** but implementation uses a **scope-based plugin architecture**. Spec is outdated and misleading.

**Spec Says** (outdated):
- Profile-based configuration management
- Generic installer abstraction layer
- Registry manager for server catalog
- Documentation parser for server metadata
- Template system for configurations

**Reality** (actual implementation):
- Scope-based configuration management (better design)
- Plugin-based client architecture (more extensible)
- Direct registry catalog without manager layer
- No documentation parser (not needed)
- Configuration stored directly in scope files (simpler)

**Verdict from STATUS**: "Implementation is BETTER than spec but spec is OUTDATED"

### Acceptance Criteria

- [ ] Replace profile-based design with scope-based design
- [ ] Document plugin architecture (`MCPClientPlugin`, `ScopeHandler`)
- [ ] Document scope hierarchy and priority system
- [ ] Remove references to deleted modules (registry.manager, doc_parser)
- [ ] Update architecture diagram if present
- [ ] Document actual CLI commands (not planned commands)
- [ ] Add section on implemented features beyond spec (rescope, completion)
- [ ] Align quality standards with reality (acknowledge test debt)
- [ ] Update project structure to match actual `src/mcpi/` layout

### Technical Notes

**Key Architectural Differences to Document**:

| Spec (Outdated) | Reality (Implementation) |
|-----------------|--------------------------|
| Profile system | Scope hierarchy with priorities |
| Generic installer abstraction | Plugin-based client system |
| Registry manager module | Direct catalog with Pydantic models |
| Documentation parser | Not implemented (not needed) |
| Template system | Direct configuration in scope files |

**Files to Reference for Accurate Spec**:
- `src/mcpi/clients/base.py` - Plugin protocol definitions
- `src/mcpi/clients/manager.py` - MCPManager orchestration
- `src/mcpi/clients/claude_code.py` - Example plugin implementation
- `CLAUDE.md` - Current accurate architecture description

---

## P1-4: Implement Missing Core Command: `mcpi categories`

**Status**: Not Started
**Effort**: Small (1-2 days)
**Dependencies**: None
**Spec Reference**: PROJECT_SPEC.md lines 143-144 • **Status Reference**: STATUS-2025-10-28-063053.md lines 41-47

### Description

PROJECT_SPEC requires `mcpi categories` command to list server categories, but it's **not implemented**. This is a simple discovery command.

**Current State**:
- Spec says: `mcpi categories` - List server categories
- Reality: Command doesn't exist
- Impact: LOW (can discover via list/search, but missing convenience)

**Registry Already Has Categories**: `data/registry.json` has category data per server.

### Acceptance Criteria

- [ ] Add `categories` command to `src/mcpi/cli.py`
- [ ] Command lists all unique categories from registry
- [ ] Output formatted as table with Rich
- [ ] Show count of servers per category
- [ ] Add `--verbose` flag to show servers in each category
- [ ] Add to `mcpi --help` output
- [ ] Write unit tests for command
- [ ] Update README with command documentation

### Technical Notes

**Implementation**:
```python
@main.command()
def categories():
    """List all MCP server categories."""
    catalog = get_server_catalog()
    # Extract unique categories from all servers
    # Count servers per category
    # Display in Rich table
```

**Output Format**:
```
MCP Server Categories
┌────────────────┬───────┐
│ Category       │ Count │
├────────────────┼───────┤
│ filesystem     │ 5     │
│ database       │ 3     │
│ api            │ 7     │
└────────────────┴───────┘
```

---

## P1-5: Implement Missing Core Command: `mcpi update`

**Status**: Not Started
**Effort**: Medium (3-5 days)
**Dependencies**: P1-1 (installation system working)
**Spec Reference**: PROJECT_SPEC.md line 148 • **Status Reference**: STATUS-2025-10-28-063053.md lines 60-67

### Description

PROJECT_SPEC requires `mcpi update <server>` to update servers to latest version, but it's **not implemented**.

**Complexity**: Higher than `categories` - requires:
1. Detecting current installed version
2. Fetching latest version from registry
3. Comparing versions
4. Executing update via appropriate method (npm, pip, etc.)
5. Preserving configuration during update

### Acceptance Criteria

- [ ] Add `update` command to CLI
- [ ] Command detects current server version
- [ ] Command checks registry for latest version
- [ ] Command compares and shows if update available
- [ ] Command performs update via correct installation method
- [ ] Command preserves server configuration (args, env vars)
- [ ] Add `--check` flag to only check for updates (dry-run)
- [ ] Add `--all` flag to update all servers
- [ ] Handle error: server not installed
- [ ] Handle error: already on latest version
- [ ] Write comprehensive tests
- [ ] Update README with command documentation

### Technical Notes

**Challenges**:
- Version detection requires querying npm registry, pip index, git tags, etc.
- Different installation methods have different update mechanisms
- Config preservation requires backup/restore logic
- Rollback needed if update fails

**Phased Implementation**:
1. Phase 1: Basic update for npm packages (majority of servers)
2. Phase 2: Support pip/uv packages
3. Phase 3: Support git repositories
4. Phase 4: Batch updates with `--all`

**Alternative**: Could be P2 instead of P1 if timeline tight.

---

## P1-6: Fix `mcpi status` Command

**Status**: Not Started
**Effort**: Small (1-2 days)
**Dependencies**: P1-1 (installation system verified)
**Spec Reference**: PROJECT_SPEC.md line 149 • **Status Reference**: STATUS-2025-10-28-063053.md lines 60-67

### Description

`mcpi status` command exists but tests fail. Need to verify if it works and fix if broken.

**From STATUS**:
- Command exists at cli.py line 1295
- Test `test_status_command_with_servers` FAILED
- Unclear if functional or broken

### Acceptance Criteria

- [ ] Manually test `mcpi status` command
- [ ] If broken: fix implementation
- [ ] If working: fix tests
- [ ] Command shows all installed servers across all scopes
- [ ] Command shows server state (ENABLED/DISABLED)
- [ ] Command shows installation method
- [ ] Add `--scope` flag to filter by scope
- [ ] Add `--client` flag to filter by client
- [ ] Tests pass for status command
- [ ] Update README documentation

### Technical Notes

**Expected Output**:
```
MCP Server Status
┌──────────────┬────────────┬─────────────┬─────────┐
│ Server       │ Scope      │ State       │ Method  │
├──────────────┼────────────┼─────────────┼─────────┤
│ filesystem   │ project    │ ENABLED     │ npx     │
│ playwright   │ user       │ ENABLED     │ pnpm    │
└──────────────┴────────────┴─────────────┴─────────┘
```

---

### P2: IMPORTANT (Quality and Completeness)

These items improve quality and user experience but aren't MVP blockers.

---

## P2-1: Refactor cli.py (God Object - 1,381 LOC)

**Status**: Not Started
**Effort**: Medium (3-5 days)
**Dependencies**: P0-1, P1-1 (tests working, understand structure)
**Spec Reference**: CLAUDE.md Code Quality • **Status Reference**: STATUS-2025-10-28-063053.md lines 385-394

### Description

`cli.py` is **1,381 lines** - a god object that should be split into logical modules. STATUS identifies this as a "code smell".

**Current Structure** (monolithic):
- All CLI commands in one file
- Rescope logic inline (lines ~984+)
- Completion logic inline (lines ~1334+)
- Scope validation inline (lines 112-198)

**Target Structure** (modular):
```
src/mcpi/cli/
  __init__.py          # Main CLI entry, command groups
  commands/
    __init__.py
    registry.py        # list, search, info, categories
    management.py      # add, remove, status, update
    scopes.py          # rescope, scope list/show
    client.py          # client list/show
    completion.py      # completion install/uninstall
  validation.py        # DynamicScopeType, validators
  formatting.py        # Rich table helpers
```

### Acceptance Criteria

- [ ] Split cli.py into logical modules (max 500 LOC per file)
- [ ] Extract rescope logic to `cli/commands/scopes.py`
- [ ] Extract completion logic to `cli/commands/completion.py`
- [ ] Extract registry commands to `cli/commands/registry.py`
- [ ] Extract management commands to `cli/commands/management.py`
- [ ] Extract validation logic to `cli/validation.py`
- [ ] Extract formatting helpers to `cli/formatting.py`
- [ ] Update imports in tests
- [ ] All tests still pass after refactor
- [ ] CLI still works: `mcpi --help` shows all commands
- [ ] No functional changes (pure refactor)

### Technical Notes

**Risk**: Large refactor with high chance of breaking tests.

**Mitigation**:
1. Only do after P0-1 (tests working)
2. Do incrementally: one command group at a time
3. Run tests after each move
4. Use git to track each step for easy rollback

**Benefits**:
- Easier to navigate and maintain
- Clearer separation of concerns
- Easier to add new commands
- Better for onboarding new contributors

---

## P2-2: Add Missing Tests for Installation Workflows

**Status**: Not Started
**Effort**: Medium (3-5 days)
**Dependencies**: P1-1 (installation system working)
**Spec Reference**: CLAUDE.md Testing Strategy • **Status Reference**: STATUS-2025-10-28-063053.md lines 145-180

### Description

Once installation system verified working (P1-1), add comprehensive integration tests for real workflows:

**Missing Coverage**:
- End-to-end: search → install → verify → remove
- Installation methods: npm, pip, uv, git
- Error scenarios: failed installs, rollback
- Scope interactions: install to different scopes

**Current State**:
- Installer tests broken (11 files fail on `ServerInstallation` import)
- Integration tests missing or obsolete

### Acceptance Criteria

- [ ] Write `tests/test_installer_integration.py` with real workflows
- [ ] Test: Install npm package server
- [ ] Test: Install Python package server
- [ ] Test: Install git repository server
- [ ] Test: Install to project scope vs user scope
- [ ] Test: Rollback on failed installation
- [ ] Test: Detect and report installation errors
- [ ] Test: Verify installed server appears in list
- [ ] Test: Uninstall removes from config cleanly
- [ ] Achieve 80%+ coverage of installation code
- [ ] All new tests pass

### Technical Notes

**Test Harness Pattern** (from STATUS):
The codebase has a test harness pattern in `tests/test_harness.py` - use this for complex integration scenarios.

**Real vs Mock**:
- Use real temporary directories
- Use real config files (`.mcp.json`, `settings.json`)
- Mock external network calls (npm registry, pip index)
- Don't actually install packages globally (use isolated test environments)

---

## P2-3: Implement Missing Advanced Features (doctor, backup, restore, sync)

**Status**: Not Started
**Effort**: Large (1-2 weeks)
**Dependencies**: P1-1, P1-2, P1-3 (core stable)
**Spec Reference**: PROJECT_SPEC.md lines 157-161 • **Status Reference**: STATUS-2025-10-28-063053.md lines 96-103

### Description

PROJECT_SPEC lists advanced features that are **not implemented**:
- `mcpi doctor` - Diagnose issues
- `mcpi backup` - Backup configuration
- `mcpi restore` - Restore from backup
- `mcpi sync` - Sync with remote registry

**Impact**: LOW (nice-to-have, not MVP blockers)

**Recommendation**: Defer to post-1.0 unless timeline allows.

### Acceptance Criteria

**(Only if time permits after P0 and P1 complete)**

**Doctor Command**:
- [ ] Check for common issues (missing dependencies, invalid configs)
- [ ] Verify MCP clients installed correctly
- [ ] Validate all server configurations
- [ ] Report actionable recommendations

**Backup Command**:
- [ ] Backup all scope configuration files
- [ ] Create timestamped backup directory
- [ ] Include metadata about backup

**Restore Command**:
- [ ] List available backups
- [ ] Restore from selected backup
- [ ] Verify restoration successful

**Sync Command**:
- [ ] Fetch latest registry from remote source
- [ ] Update `data/registry.json`
- [ ] Show diff of changes

### Technical Notes

**Priority Order** (if implementing):
1. `doctor` - Most useful for user support
2. `backup` - Risk mitigation for users
3. `restore` - Required if backup exists
4. `sync` - Lowest priority (registry manually maintained currently)

**Alternative**: Ship 1.0 without these, add in 1.1+

---

## P2-4: Achieve 80%+ Test Coverage with Passing Tests

**Status**: Not Started
**Effort**: Medium (3-5 days)
**Dependencies**: P0-1, P1-1, P2-2 (tests fixed and added)
**Spec Reference**: PROJECT_SPEC.md line 197 (95% target) • **Status Reference**: STATUS-2025-10-28-063053.md lines 550-582

### Description

PROJECT_SPEC targets **95% test coverage** but STATUS shows we can't even measure coverage due to broken tests.

**Current Reality**:
- Cannot measure coverage (31% of tests don't import)
- Unknown actual coverage percentage
- Many tests are tautological or broken

**Realistic Target**:
- 80% coverage with meaningful tests (vs 95% with broken tests)
- Focus on un-gameable functional tests
- Test real functionality, not implementation details

### Acceptance Criteria

- [ ] All tests import and run successfully
- [ ] Achieve 80%+ line coverage: `pytest --cov=src/mcpi --cov-report=html`
- [ ] Achieve 70%+ branch coverage
- [ ] No tautological tests (tests that always pass)
- [ ] Focus on functional tests over unit tests where appropriate
- [ ] Test error paths, not just happy paths
- [ ] Integration tests for critical workflows
- [ ] Coverage report shows which areas need tests

### Technical Notes

**Coverage Measurement**:
```bash
# After fixing tests
pytest --cov=src/mcpi --cov-report=html --cov-report=term

# Review HTML report
open htmlcov/index.html

# Focus on areas <80% coverage
```

**Test Quality Over Quantity**:
- One good integration test > 10 unit tests mocking everything
- See `tests/test_cli_rescope.py` for example of quality tests (27/28 passing)
- See `tests/test_cli_completion.py` for un-gameable functional tests (69/72 passing)

---

### P3: NICE-TO-HAVE (Improvements and Polish)

These items improve quality of life but aren't required for 1.0.

---

## P3-1: Add CI/CD Pipeline

**Status**: Not Started
**Effort**: Small (1-2 days)
**Dependencies**: P0-1 (tests working)
**Spec Reference**: N/A (infrastructure) • **Status Reference**: STATUS-2025-10-28-063053.md lines 425-436

### Description

**No CI/CD exists** - tests can break unnoticed. Add automated testing on commits.

**Current Risk**: STATUS shows "No CI/CD catching regressions" as HIGH severity.

### Acceptance Criteria

- [ ] Create `.github/workflows/test.yml` (if using GitHub)
- [ ] Run tests on every push and PR
- [ ] Run linter (ruff) on every push
- [ ] Run type checker (mypy) on every push
- [ ] Run on Python 3.9, 3.10, 3.11, 3.12
- [ ] Badge in README showing test status
- [ ] Block PRs if tests fail
- [ ] Generate coverage report in CI

### Technical Notes

**GitHub Actions Workflow**:
```yaml
name: Tests
on: [push, pull_request]
jobs:
  test:
    runs-on: ubuntu-latest
    strategy:
      matrix:
        python-version: ["3.9", "3.10", "3.11", "3.12"]
    steps:
      - uses: actions/checkout@v3
      - uses: actions/setup-python@v4
        with:
          python-version: ${{ matrix.python-version }}
      - run: pip install uv
      - run: uv sync
      - run: pytest --cov=src/mcpi
      - run: ruff check src/ tests/
      - run: mypy src/
```

**Quick Win**: Prevents future test regressions.

---

## P3-2: Implement Tab Completion for More Shells

**Status**: Not Started
**Effort**: Small (1-2 days)
**Dependencies**: None
**Spec Reference**: N/A (enhancement) • **Status Reference**: STATUS-2025-10-28-063053.md lines 109-113

### Description

`mcpi completion` exists for bash/zsh/fish but could add more shells.

**Current State**:
- Completion command implemented (69/72 tests passing)
- Supports bash, zsh, fish
- Could add: PowerShell, Nushell, etc.

**Impact**: LOW (current shells cover majority of users)

### Acceptance Criteria

- [ ] Add PowerShell completion support
- [ ] Add Nushell completion support
- [ ] Test completion in each shell
- [ ] Update README with new shell instructions
- [ ] All completion tests pass

### Technical Notes

**Priority**: Very low - only if everything else done and time to spare.

**Alternative**: Ship 1.0 with current shells, add more in 1.x based on user requests.

---

## P3-3: Create Architecture Documentation for Contributors

**Status**: Not Started
**Effort**: Small (1-2 days)
**Dependencies**: P1-3 (PROJECT_SPEC updated)
**Spec Reference**: N/A (documentation) • **Status Reference**: STATUS-2025-10-28-063053.md lines 366-382

### Description

Create `ARCHITECTURE.md` documenting the plugin-based scope system for new contributors.

**Current State**:
- Plugin architecture not documented anywhere except CLAUDE.md
- New contributors would be confused by scope vs profile terminology
- No diagrams showing data flow

### Acceptance Criteria

- [ ] Create `ARCHITECTURE.md` in repo root
- [ ] Document plugin architecture (MCPClientPlugin protocol)
- [ ] Document scope hierarchy and priorities
- [ ] Document data flow (client detection → scope resolution → operations)
- [ ] Add diagrams (ASCII or mermaid) showing architecture
- [ ] Explain design decisions (why scopes > profiles)
- [ ] Document how to add new MCP client plugins
- [ ] Link from README to ARCHITECTURE.md

### Technical Notes

**Content Outline**:
1. Overview of plugin-based design
2. Core abstractions (MCPClientPlugin, ScopeHandler)
3. Scope hierarchy and priority system
4. Data models (ServerInfo, ServerConfig, OperationResult)
5. Adding a new client plugin (tutorial)
6. Design principles and patterns

---

## P3-4: Clean Remaining Technical Debt (171+ broken references)

**Status**: Not Started
**Effort**: Medium (3-5 days)
**Dependencies**: P0-1, P0-2 (major cleanup done)
**Spec Reference**: N/A (cleanup) • **Status Reference**: STATUS-2025-10-28-063053.md from prior audit

### Description

Previous STATUS report mentioned **171+ references to deleted modules**. After P0-1 and P0-2, there may still be references in:
- Comments
- Documentation
- Deprecated code paths
- Type hints

### Acceptance Criteria

- [ ] Search for all references to deleted modules
- [ ] Update or remove each reference
- [ ] Run linter to catch remaining issues
- [ ] Run type checker to catch broken type hints
- [ ] Clean up commented-out code
- [ ] Verify no broken links in documentation
- [ ] Target: <5 acceptable references (in migration notes, etc.)

### Technical Notes

**Search Commands**:
```bash
# Find references to known-deleted items
git grep -n "ClaudeCodeInstaller"
git grep -n "registry.manager"
git grep -n "registry.doc_parser"
git grep -n "ServerInstallation"
git grep -n "get_method_string"
```

**Decision Framework**:
- Code references → Fix or delete
- Comment references → Update or delete
- Documentation → Update
- Migration notes → Keep (explain what replaced it)

---

## Recommended Sprint Organization

### Sprint 1: Test Infrastructure Repair (Week 1)

**Goal**: Get test suite functional and remove dead code
**Duration**: 5 days
**Work Items**: P0-1, P0-2, P0-3

**Daily Breakdown**:
- Day 1-2: P0-1 (Fix test imports - categorize, delete obsolete, update relevant)
- Day 3: P0-2 (Delete dead code files)
- Day 4: P0-3 (Manual verification of core functionality)
- Day 5: Verify all P0 items complete, measure progress

**Success Criteria**:
- [ ] 0 test import errors
- [ ] All core commands manually verified
- [ ] Dead code removed

---

### Sprint 2: Installation System and Documentation (Week 2)

**Goal**: Fix/verify installation, update docs to match reality
**Duration**: 5 days
**Work Items**: P1-1, P1-2, P1-3

**Daily Breakdown**:
- Day 1-2: P1-1 (Fix installation system based on P0-3 findings)
- Day 3: P1-2 (Update README - remove lies, add rescope/completion)
- Day 4-5: P1-3 (Update PROJECT_SPEC to match implementation)

**Success Criteria**:
- [ ] Installation commands work reliably
- [ ] README accurate (no false claims)
- [ ] PROJECT_SPEC matches reality

---

### Sprint 3: Complete Core Features (Week 3)

**Goal**: Implement missing MVP commands
**Duration**: 5 days
**Work Items**: P1-4, P1-5, P1-6

**Daily Breakdown**:
- Day 1: P1-4 (`mcpi categories` command)
- Day 2-3: P1-5 (`mcpi update` command - most complex)
- Day 4: P1-6 (`mcpi status` command fix)
- Day 5: Integration testing, bug fixes

**Success Criteria**:
- [ ] All core commands from spec implemented
- [ ] Commands tested and working
- [ ] Documentation updated

---

### Sprint 4: Quality and Polish (Week 4)

**Goal**: Improve code quality, coverage, infrastructure
**Duration**: 5 days
**Work Items**: P2-1, P2-2, P2-4, P3-1

**Daily Breakdown**:
- Day 1-2: P2-1 (Refactor cli.py into modules)
- Day 3: P2-2 (Add installation integration tests)
- Day 4: P2-4 (Achieve 80% coverage)
- Day 5: P3-1 (Add CI/CD)

**Success Criteria**:
- [ ] cli.py refactored (<500 LOC per module)
- [ ] 80%+ test coverage
- [ ] CI/CD running

**Optional**: P2-3, P3-2, P3-3, P3-4 if time permits

---

## Dependency Graph

```
CRITICAL PATH (Must Complete for 1.0):
P0-1 (Fix test imports)
  ↓
P0-2 (Remove dead code) [parallel with P0-1]
  ↓
P0-3 (Manual verification)
  ↓
P1-1 (Fix installation system)
  ↓
P1-2 (Update README)
  ↓
P1-3 (Update PROJECT_SPEC)
  ↓
P1-4 (categories command)
  ↓
P1-5 (update command)
  ↓
P1-6 (status command)

QUALITY PATH (Should Complete for 1.0):
P1-1 complete
  ↓
P2-1 (Refactor CLI) [can parallel with P2-2]
  ↓
P2-2 (Add integration tests)
  ↓
P2-4 (Achieve 80% coverage)
  ↓
P3-1 (Add CI/CD)

OPTIONAL PATH (Nice-to-Have for 1.0):
P1-3 complete
  ↓
P3-3 (Architecture docs)
  ↓
P3-4 (Clean remaining debt)
  ↓
P2-3 (Advanced features - doctor/backup/restore/sync)
  ↓
P3-2 (More shell completions)
```

---

## Risk Assessment

### HIGH RISK: Test Repairs Reveal Deeper Issues

**Risk**: Fixing 19 test imports may reveal that much functionality is missing or broken.

**Likelihood**: MEDIUM
**Impact**: HIGH (could extend timeline 1-2 weeks)

**Mitigation**:
- Categorize tests quickly: obsolete vs outdated
- Delete obsolete tests immediately (don't try to fix)
- Focus on core functionality tests first
- Defer edge case tests to later

**Contingency**: If >50% tests obsolete, reassess testing strategy and write new tests for current implementation.

---

### MEDIUM RISK: Installation System Actually Broken

**Risk**: P0-3 manual testing reveals installation commands fundamentally broken.

**Likelihood**: LOW (STATUS shows app works, likely test issue)
**Impact**: MEDIUM (P1-1 becomes 1-2 week effort instead of 3-5 days)

**Mitigation**:
- P0-3 discovers this early (before committing to P1-1)
- Have backup plan: ship 1.0 without installation, focus on scope management
- Installation could be 1.1 feature if fundamentally broken

**Contingency**: If broken, scope 1.0 to registry browsing + scope management only. Fix installation in 1.1.

---

### LOW RISK: Timeline Optimism

**Risk**: 4-week timeline assumes no major surprises.

**Likelihood**: MEDIUM (software always has surprises)
**Impact**: LOW (can descope features)

**Mitigation**:
- P0 and P1 items are fixed scope
- P2 items can be deferred to 1.1
- P3 items are explicitly optional

**Contingency**: Ship 1.0 with P0 + P1 complete, defer P2 and P3 to 1.x releases.

---

## Success Metrics

### Phase 1 Success (After Sprint 1)

**Test Infrastructure**:
- [ ] 0 test import errors (down from 19)
- [ ] >80% of tests execute successfully
- [ ] Can run `pytest tests/` without crashes

**Code Quality**:
- [ ] 0 dead code files (down from 3)
- [ ] Navigation clarity improved

**Functional Validation**:
- [ ] All commands manually tested
- [ ] Known working vs broken documented

---

### Phase 2 Success (After Sprint 2)

**Functionality**:
- [ ] Installation system verified working or flagged as broken
- [ ] Tests aligned with implementation

**Documentation**:
- [ ] README accurate (no false claims)
- [ ] README documents rescope and completion
- [ ] PROJECT_SPEC matches implementation architecture

---

### Phase 3 Success (After Sprint 3)

**Feature Completeness**:
- [ ] `mcpi categories` implemented and tested
- [ ] `mcpi update` implemented and tested
- [ ] `mcpi status` fixed and tested
- [ ] All core commands from spec working

---

### Final Success (1.0 Release)

**Completion Criteria**:
- [ ] All P0 and P1 items complete
- [ ] Test suite healthy (>80% pass rate)
- [ ] 80%+ code coverage
- [ ] CI/CD running
- [ ] Documentation accurate
- [ ] No known data corruption bugs
- [ ] Installation system functional

**Quality Gates**:
- [ ] Can install real MCP server from registry
- [ ] Can move servers between scopes
- [ ] Can browse and search registry
- [ ] All documented features work
- [ ] No misleading documentation

---

## Timeline to 1.0

**Conservative Estimate**: 4 weeks (20 business days)

**Breakdown**:
- Sprint 1 (P0 items): 5 days
- Sprint 2 (P1 documentation): 5 days
- Sprint 3 (P1 features): 5 days
- Sprint 4 (P2 quality): 5 days

**Optimistic Estimate**: 3 weeks (if no surprises)

**Realistic Estimate**: 4-5 weeks (accounting for debugging, integration issues)

**Critical Path**: P0 → P1 → Sprint 4 = 15 days minimum

---

## What Gets Deferred to Post-1.0

**If timeline pressure**:
- P2-3: Advanced features (doctor, backup, restore, sync) → 1.1
- P3-2: Additional shell completions → 1.x
- P3-3: Architecture documentation → 1.1
- P3-4: Remaining technical debt → 1.1

**MVP for 1.0**:
- Working test suite ✓
- Accurate documentation ✓
- Core registry commands (list, search, info, categories) ✓
- Core management commands (add, remove, status, update) ✓
- Scope management (rescope, scope list/show) ✓
- Tab completion (current shells) ✓
- Installation system functional ✓
- 80% test coverage ✓
- CI/CD ✓

---

## Key Insights from STATUS

**What STATUS Revealed**:
1. **Architecture is solid** - Plugin design is good, scope system works
2. **Recent features are high quality** - Rescope and completion well-tested
3. **Test infrastructure neglected** - 31% broken indicates tests not run regularly
4. **Documentation drift** - README describes features that don't exist
5. **Spec drift** - Spec describes different architecture than implemented

**What This Means**:
- Foundation is good, just needs cleaning
- Can ship quality 1.0 with focused effort
- Need CI/CD to prevent test decay
- Need to keep docs in sync with code

**Positive Takeaways**:
- Core functionality works (68% complete)
- Recent work shows team can ship quality features
- Architecture is better than spec (scope system > profile system)
- Clear path to 1.0 (fix tests, align docs, complete features)

---

## Next Actions

**Immediate** (This Week):
1. Start P0-1: Categorize broken test files
2. Start P0-2: Delete dead code files (quick win)
3. Review this plan for accuracy

**This Month**:
1. Complete Sprint 1 (P0 items)
2. Complete Sprint 2 (P1 documentation)
3. Begin Sprint 3 (P1 features)

**This Quarter**:
1. Ship 1.0 with all P0 and P1 items
2. Begin P2 and P3 items for 1.1

**Do NOT**:
1. Add new features until test infrastructure fixed
2. Claim completion percentages without running tests
3. Skip test fixes to rush new features
4. Ignore documentation drift

---

**END OF PLAN**

This plan provides a realistic, evidence-based path to production-ready 1.0 based on actual current state per STATUS-2025-10-28-063053.md.
