# MCPI Test Fixes - Complete Backlog

**Generated**: 2025-11-16 15:01:58
**Source STATUS**: STATUS-2025-11-16-145839.md
**Spec Version**: CLAUDE.md (last modified 2025-11-16)
**Goal**: Fix all 15 failing tests to achieve 100% pass rate (677/677)

---

## Executive Summary

### Current State
- **Total Tests**: 692 (677 active, 15 skipped)
- **Passing**: 662/677 (97.8%)
- **Failing**: 15/677 (2.2%)
- **Production Bugs**: 0 (all failures are test bugs)
- **Production Status**: Ready to ship

### Total Gap
**15 failing tests** organized into 3 categories:
1. **API Type Mismatch** (8 tests) - Tests pass dict, should pass ServerConfig
2. **Test Harness Issues** (2 tests) - Wrong server counts in fixtures
3. **Test Infrastructure** (5 tests) - Various setup issues

### Effort Summary
- **Total Estimated Effort**: 4-6 hours
- **Phase 1 (Quick Wins)**: 2-3 hours (10 tests)
- **Phase 2 (Infrastructure)**: 2-3 hours (5 tests)

### Recommended Focus
1. Start with Phase 1 (mechanical fixes, high confidence)
2. Complete Phase 2 (requires investigation)
3. Verify 100% pass rate
4. Ship v2.0 with zero compromises

---

## P0 (Critical) - Quick Wins: API Type Mismatch Fixes

### P0-1: Fix Type Mismatch in test_functional_critical_workflows.py (3 tests)

**Status**: Not Started
**Effort**: Small (30-45 minutes)
**Dependencies**: None
**Spec Reference**: CLAUDE.md § File-Based Scope API • **Status Reference**: STATUS-2025-11-16-145839.md § Category 1

#### Description

Three tests in `test_functional_critical_workflows.py` pass `dict` objects to `update_server()` which requires `ServerConfig` objects. This violates the API contract defined in `src/mcpi/clients/file_based.py:317`.

**Root Cause**: Test code uses wrong type for API parameter.

**Evidence**:
```python
# File: tests/test_functional_critical_workflows.py:426
# CURRENT (WRONG):
updated_config = {  # ❌ dict instead of ServerConfig
    "command": "node",
    "args": ["updated-filesystem.js"],
    "type": "stdio",
}
result = scope_handler.update_server("filesystem", updated_config)
# Error: 'dict' object has no attribute 'to_dict'
```

**Fix Required**:
```python
# CORRECTED:
from mcpi.clients.types import ServerConfig

updated_config = ServerConfig(
    command="node",
    args=["updated-filesystem.js"],
    type="stdio"
)
result = scope_handler.update_server("filesystem", updated_config)
```

#### Acceptance Criteria
- [ ] All 3 tests in `test_functional_critical_workflows.py` pass
- [ ] Import `ServerConfig` from `mcpi.clients.types` added to file
- [ ] All `update_server()` calls use `ServerConfig` objects instead of dicts
- [ ] Test assertions remain unchanged (only parameter type changes)
- [ ] Run `pytest tests/test_functional_critical_workflows.py -v` - all pass

#### Affected Tests
1. `test_functional_critical_workflows.py::TestCoreUserWorkflows::test_add_and_remove_server_workflow`
2. `test_functional_critical_workflows.py::TestCoreUserWorkflows::test_update_server_preserves_other_servers`
3. `test_functional_critical_workflows.py::TestManagerIntegration::test_manager_get_servers_aggregates_across_scopes`

#### Technical Notes
- This is a **mechanical fix** - same pattern repeated 3 times
- Search for all `update_server(` calls in the file
- Replace dict literals with `ServerConfig()` constructor calls
- Preserve all existing assertions and test logic
- No production code changes required

#### Implementation Locations
**File**: `/Users/bmf/icode/mcpi/tests/test_functional_critical_workflows.py`

**Line Numbers** (approximate, search for exact locations):
- Line ~426: `test_add_and_remove_server_workflow`
- Line ~460: `test_update_server_preserves_other_servers`
- Line ~510: `test_manager_get_servers_aggregates_across_scopes`

---

### P0-2: Fix Type Mismatch in test_functional_user_workflows.py (3 tests)

**Status**: Not Started
**Effort**: Small (30-45 minutes)
**Dependencies**: None
**Spec Reference**: CLAUDE.md § File-Based Scope API • **Status Reference**: STATUS-2025-11-16-145839.md § Category 1

#### Description

Three tests in `test_functional_user_workflows.py` pass `dict` objects to `update_server()` which requires `ServerConfig` objects. Same root cause as P0-1, different file.

**Root Cause**: Test code uses wrong type for API parameter.

**Fix Required**: Same pattern as P0-1:
```python
# Add import:
from mcpi.clients.types import ServerConfig

# Replace all dict literals with ServerConfig objects:
# Before:
config = {"command": "node", "args": ["file.js"], "type": "stdio"}

# After:
config = ServerConfig(command="node", args=["file.js"], type="stdio")
```

#### Acceptance Criteria
- [ ] All 3 tests in `test_functional_user_workflows.py` pass
- [ ] Import `ServerConfig` from `mcpi.clients.types` added to file
- [ ] All `update_server()` calls use `ServerConfig` objects instead of dicts
- [ ] Test assertions remain unchanged (only parameter type changes)
- [ ] Run `pytest tests/test_functional_user_workflows.py -v` - all pass

#### Affected Tests
1. `test_functional_user_workflows.py::TestServerLifecycleWorkflows::test_server_state_management_workflow`
2. `test_functional_user_workflows.py::TestMultiScopeWorkflows::test_multi_scope_aggregation_workflow`
3. `test_functional_user_workflows.py::TestMultiScopeWorkflows::test_scope_precedence_workflow`

#### Technical Notes
- Same mechanical fix as P0-1
- Search for all `update_server(` calls in the file
- Replace dict literals with `ServerConfig()` constructor calls
- No production code changes required

#### Implementation Locations
**File**: `/Users/bmf/icode/mcpi/tests/test_functional_user_workflows.py`

**Search Pattern**: `update_server(` to find all call sites

---

### P0-3: Fix Type Mismatch in test_cli_scope_features.py (2 tests)

**Status**: Not Started
**Effort**: Small (20-30 minutes)
**Dependencies**: None
**Spec Reference**: CLAUDE.md § File-Based Scope API • **Status Reference**: STATUS-2025-11-16-145839.md § Category 1

#### Description

Two tests in `test_cli_scope_features.py` pass `dict` objects to `update_server()` which requires `ServerConfig` objects. Same root cause as P0-1 and P0-2.

**Root Cause**: Test code uses wrong type for API parameter.

**Fix Required**: Same pattern as P0-1 and P0-2:
```python
# Add import:
from mcpi.clients.types import ServerConfig

# Replace all dict literals with ServerConfig objects
```

#### Acceptance Criteria
- [ ] All 2 tests in `test_cli_scope_features.py` pass
- [ ] Import `ServerConfig` from `mcpi.clients.types` added to file
- [ ] All `update_server()` calls use `ServerConfig` objects instead of dicts
- [ ] Test assertions remain unchanged (only parameter type changes)
- [ ] Run `pytest tests/test_cli_scope_features.py::TestInteractiveScopeSelection -v` - all pass

#### Affected Tests
1. `test_cli_scope_features.py::TestInteractiveScopeSelection::test_add_command_interactive_scope_selection`
2. `test_cli_scope_features.py::TestInteractiveScopeSelection::test_add_command_dry_run_auto_scope`

#### Technical Notes
- Same mechanical fix as P0-1 and P0-2
- Search for all `update_server(` calls in the file
- This is the test class `TestInteractiveScopeSelection` specifically
- No production code changes required

#### Implementation Locations
**File**: `/Users/bmf/icode/mcpi/tests/test_cli_scope_features.py`

**Search Pattern**: `update_server(` within `TestInteractiveScopeSelection` class

---

### P0-4: Fix Test Harness Fixture Server Counts (2 tests)

**Status**: Not Started
**Effort**: Small (30 minutes)
**Dependencies**: None
**Spec Reference**: CLAUDE.md § Testing Strategy • **Status Reference**: STATUS-2025-11-16-145839.md § Category 2

#### Description

Two tests in `test_harness_example.py` fail due to incorrect expected server counts. The `prepopulated_harness` fixture creates 2 servers in the `user-internal` scope, but tests expect 1.

**Root Cause**: Test fixture and test expectations are out of sync.

**Evidence**:
```python
# File: tests/test_harness_example.py:83
def test_count_servers(self, prepopulated_harness):
    assert prepopulated_harness.count_servers_in_scope("user-internal") == 1
    # AssertionError: assert 2 == 1
    # Actual: 2 servers in scope
    # Expected: 1 server in scope
```

**Investigation Required**:
1. Inspect `prepopulated_harness` fixture definition
2. Determine correct server count (is it actually 1 or 2?)
3. Choose fix approach:
   - **Option A**: Update fixture to create 1 server (if 1 is correct)
   - **Option B**: Update test assertions to expect 2 (if 2 is correct)

#### Acceptance Criteria
- [ ] Investigate `prepopulated_harness` fixture in `conftest.py` or `test_harness.py`
- [ ] Document actual vs expected server counts
- [ ] Update either fixture OR test assertions (not both)
- [ ] Both tests pass: `pytest tests/test_harness_example.py -v`
- [ ] Add comment explaining the correct count

#### Affected Tests
1. `test_harness_example.py::TestMCPHarnessBasics::test_count_servers`
2. `test_harness_example.py::TestMCPManagerIntegration::test_list_servers_from_prepopulated`

#### Technical Notes
- **Investigation First**: Don't guess - determine ground truth
- Check `conftest.py` and `tests/test_harness.py` for fixture definition
- The fixture name is `prepopulated_harness`
- Look for calls to `add_server()` or similar in fixture setup
- Whichever approach you choose (A or B), document why in a comment

#### Implementation Locations
**Fixture**: `/Users/bmf/icode/mcpi/tests/conftest.py` OR `/Users/bmf/icode/mcpi/tests/test_harness.py`
**Tests**: `/Users/bmf/icode/mcpi/tests/test_harness_example.py`

---

## P1 (High) - Infrastructure Fixes: Test Setup & Mocking

### P1-1: Fix Installer Validation Test

**Status**: Not Started
**Effort**: Medium (45-60 minutes)
**Dependencies**: None
**Spec Reference**: CLAUDE.md § Testing Strategy • **Status Reference**: STATUS-2025-11-16-145839.md § Category 3

#### Description

Test `test_installer.py::TestBaseInstaller::test_validate_installation` fails due to missing or incomplete validation functionality in the test environment.

**Root Cause**: Test expects validation functionality that may not be fully implemented or mocked.

**Investigation Required**:
1. Read the failing test to understand what it expects
2. Determine if validation is implemented in production code
3. Determine if test needs better mocking or if implementation is missing
4. Fix either test setup or mock infrastructure

#### Acceptance Criteria
- [ ] Read `test_installer.py::TestBaseInstaller::test_validate_installation`
- [ ] Understand what validation functionality is expected
- [ ] Verify if `BaseInstaller.validate_installation()` exists and works
- [ ] Implement missing mocks OR fix test setup
- [ ] Test passes: `pytest tests/test_installer.py::TestBaseInstaller::test_validate_installation -v`
- [ ] Document the fix in a comment

#### Affected Tests
1. `test_installer.py::TestBaseInstaller::test_validate_installation`

#### Technical Notes
- This requires **investigation** before fixing
- Check if `BaseInstaller` class has `validate_installation()` method
- If method exists, check if test has proper mocks for filesystem/subprocess
- If method doesn't exist, test may be testing future functionality (skip or implement)
- May need to mock `subprocess.run()` or file existence checks

#### Implementation Locations
**Test**: `/Users/bmf/icode/mcpi/tests/test_installer.py`
**Production**: `/Users/bmf/icode/mcpi/src/mcpi/installer.py` (if exists)

---

### P1-2: Fix Installer Workflow State Transition Test

**Status**: Not Started
**Effort**: Medium (45-60 minutes)
**Dependencies**: None
**Spec Reference**: CLAUDE.md § Testing Strategy, MCPTestHarness • **Status Reference**: STATUS-2025-11-16-145839.md § Category 3

#### Description

Test `test_installer_workflows_integration.py::TestInstallerWorkflowsWithHarness::test_server_state_transitions` fails due to test harness integration issues.

**Root Cause**: Test requires specific server state transitions that may not be properly mocked or set up in the test harness.

**Investigation Required**:
1. Read the failing test to understand state transition expectations
2. Check if test harness properly initializes server states
3. Verify if state transition logic is mocked correctly
4. Fix test harness setup or mock infrastructure

#### Acceptance Criteria
- [ ] Read `test_installer_workflows_integration.py::TestInstallerWorkflowsWithHarness::test_server_state_transitions`
- [ ] Understand expected state transitions (e.g., DISABLED → ENABLED)
- [ ] Verify test harness sets up initial states correctly
- [ ] Verify state transition mocks or real implementation works
- [ ] Test passes: `pytest tests/test_installer_workflows_integration.py::TestInstallerWorkflowsWithHarness::test_server_state_transitions -v`
- [ ] Document the fix in a comment

#### Affected Tests
1. `test_installer_workflows_integration.py::TestInstallerWorkflowsWithHarness::test_server_state_transitions`

#### Technical Notes
- Uses `MCPTestHarness` - review harness initialization
- May need to review `ServerState` enum and state management logic
- Check if test expectations match production state machine
- May need to add state setup in harness fixture

#### Implementation Locations
**Test**: `/Users/bmf/icode/mcpi/tests/test_installer_workflows_integration.py`
**Harness**: `/Users/bmf/icode/mcpi/tests/test_harness.py`

---

### P1-3: Fix Rescope Error Handling Test

**Status**: Not Started
**Effort**: Small (30-45 minutes)
**Dependencies**: None
**Spec Reference**: CLAUDE.md § Testing Strategy • **Status Reference**: STATUS-2025-11-16-145839.md § Category 3

#### Description

Test `test_rescope_aggressive.py::TestRescopeAggressiveErrorHandling::test_rescope_add_fails_does_not_remove_from_sources` fails due to error handling mock setup issues.

**Root Cause**: Test requires specific error handling paths that may not be properly mocked.

**Investigation Required**:
1. Read the failing test to understand error scenario
2. Verify error mocking (should fail add, should NOT remove)
3. Fix mock setup to properly simulate failure

#### Acceptance Criteria
- [ ] Read `test_rescope_aggressive.py::TestRescopeAggressiveErrorHandling::test_rescope_add_fails_does_not_remove_from_sources`
- [ ] Understand the error scenario being tested
- [ ] Verify mock setup properly simulates "add fails"
- [ ] Verify test checks "remove was NOT called"
- [ ] Test passes: `pytest tests/test_rescope_aggressive.py::TestRescopeAggressiveErrorHandling::test_rescope_add_fails_does_not_remove_from_sources -v`
- [ ] Document the fix in a comment

#### Affected Tests
1. `test_rescope_aggressive.py::TestRescopeAggressiveErrorHandling::test_rescope_add_fails_does_not_remove_from_sources`

#### Technical Notes
- This is testing **error handling** (rollback behavior)
- When rescope add fails, should NOT remove from source scope
- May need to use `unittest.mock.patch()` to simulate failure
- Verify assertions check that remove was NOT called (use `assert_not_called()`)

#### Implementation Locations
**Test**: `/Users/bmf/icode/mcpi/tests/test_rescope_aggressive.py`

---

### P1-4: Fix TUI Reload Client Context Test

**Status**: Not Started
**Effort**: Medium (45-60 minutes)
**Dependencies**: None
**Spec Reference**: CLAUDE.md § TUI Architecture • **Status Reference**: STATUS-2025-11-16-145839.md § Category 3

#### Description

Test `test_tui_reload.py::TestTuiReloadCLICommand::test_tui_reload_respects_client_context` fails due to TUI component setup issues.

**Root Cause**: Test interacts with TUI components requiring complex setup (Click context, FZF adapter, client context).

**Investigation Required**:
1. Read the failing test to understand TUI interaction
2. Check if Click context is properly initialized
3. Check if client context (claude-code, cursor, etc.) is set correctly
4. Fix test setup or mocking

#### Acceptance Criteria
- [ ] Read `test_tui_reload.py::TestTuiReloadCLICommand::test_tui_reload_respects_client_context`
- [ ] Understand TUI reload functionality being tested
- [ ] Verify Click CLI context is properly initialized
- [ ] Verify client context is set correctly in test
- [ ] Test passes: `pytest tests/test_tui_reload.py::TestTuiReloadCLICommand::test_tui_reload_respects_client_context -v`
- [ ] Document the fix in a comment

#### Affected Tests
1. `test_tui_reload.py::TestTuiReloadCLICommand::test_tui_reload_respects_client_context`

#### Technical Notes
- TUI tests are complex - involve Click, FZF, and client state
- May need to mock `FzfAdapter` or use test double
- Review recent TUI fixes (see commit `491e3cd` in STATUS)
- Check if `--client` flag is properly passed through to reload

#### Implementation Locations
**Test**: `/Users/bmf/icode/mcpi/tests/test_tui_reload.py`
**TUI Code**: `/Users/bmf/icode/mcpi/src/mcpi/tui/adapters/fzf.py`

---

### P1-5: Fix FZF Reload Integration Test

**Status**: Not Started
**Effort**: Medium (45-60 minutes)
**Dependencies**: None
**Spec Reference**: CLAUDE.md § TUI Architecture • **Status Reference**: STATUS-2025-11-16-145839.md § Category 3

#### Description

Test `test_tui_reload.py::TestFzfIntegrationWithReload::test_operation_changes_reflected_in_reload` fails due to FZF reload mechanism integration issues.

**Root Cause**: Test expects operations (add/remove server) to be reflected in FZF reload, but integration may not be properly set up.

**Investigation Required**:
1. Read the failing test to understand reload expectation
2. Verify FZF adapter `reload` functionality is implemented
3. Check if test properly triggers operations and reload
4. Fix test setup or FZF adapter mocking

#### Acceptance Criteria
- [ ] Read `test_tui_reload.py::TestFzfIntegrationWithReload::test_operation_changes_reflected_in_reload`
- [ ] Understand FZF reload mechanism (see commit `7570251` in git history)
- [ ] Verify test simulates add/remove operations
- [ ] Verify test checks that reload shows updated state
- [ ] Test passes: `pytest tests/test_tui_reload.py::TestFzfIntegrationWithReload::test_operation_changes_reflected_in_reload -v`
- [ ] Document the fix in a comment

#### Affected Tests
1. `test_tui_reload.py::TestFzfIntegrationWithReload::test_operation_changes_reflected_in_reload`

#### Technical Notes
- FZF reload feature was recently implemented (commit `7570251`)
- Test may be testing future functionality or integration
- May need to mock FZF process or use test harness
- Check if `--reload` flag works in test environment

#### Implementation Locations
**Test**: `/Users/bmf/icode/mcpi/tests/test_tui_reload.py`
**TUI Code**: `/Users/bmf/icode/mcpi/src/mcpi/tui/adapters/fzf.py`

---

## Dependency Graph

```
Phase 1 (Parallel - No Dependencies):
├── P0-1: Fix test_functional_critical_workflows.py (3 tests)
├── P0-2: Fix test_functional_user_workflows.py (3 tests)
├── P0-3: Fix test_cli_scope_features.py (2 tests)
└── P0-4: Fix test_harness_example.py (2 tests)

Phase 2 (Parallel - No Dependencies):
├── P1-1: Fix test_installer.py (1 test)
├── P1-2: Fix test_installer_workflows_integration.py (1 test)
├── P1-3: Fix test_rescope_aggressive.py (1 test)
├── P1-4: Fix test_tui_reload.py - client context (1 test)
└── P1-5: Fix test_tui_reload.py - reload integration (1 test)

Verification (Sequential - Depends on All Above):
└── Run full test suite: pytest -v
    └── Verify: 677/677 passing (100%)
```

**No blocking dependencies** - All work items can be done in parallel within their phase.

---

## Recommended Sprint Planning

### Sprint 1: Quick Wins (2-3 hours)

**Goal**: Fix all 10 mechanical/straightforward tests

**Tasks**:
1. P0-1: Fix type mismatch in test_functional_critical_workflows.py (30-45 min)
2. P0-2: Fix type mismatch in test_functional_user_workflows.py (30-45 min)
3. P0-3: Fix type mismatch in test_cli_scope_features.py (20-30 min)
4. P0-4: Fix test harness server counts (30 min)

**Success Criteria**: 10/15 tests fixed, 672/677 passing (99.3%)

---

### Sprint 2: Infrastructure Fixes (2-3 hours)

**Goal**: Fix all 5 infrastructure tests requiring investigation

**Tasks**:
1. P1-1: Fix installer validation test (45-60 min)
2. P1-2: Fix installer workflow state transition test (45-60 min)
3. P1-3: Fix rescope error handling test (30-45 min)
4. P1-4: Fix TUI reload client context test (45-60 min)
5. P1-5: Fix FZF reload integration test (45-60 min)

**Success Criteria**: 15/15 tests fixed, 677/677 passing (100%)

---

## Risk Assessment

### High Risk Items
**NONE** - All failures are well-understood test bugs.

### Medium Risk Items
1. **P1-4 & P1-5 (TUI tests)**: TUI components are complex, may need deeper investigation
2. **P1-2 (State transitions)**: State management can be tricky to test correctly

### Low Risk Items
1. **P0-1, P0-2, P0-3**: Mechanical fixes, very low risk
2. **P0-4**: Simple fixture issue
3. **P1-1, P1-3**: Standard mocking issues

### Mitigation Strategies
- Start with low-risk items to build momentum
- For medium-risk items, investigate first before attempting fix
- Run tests after each fix to verify no regressions
- If stuck on any item for >1 hour, document blocker and move to next item

---

## Success Metrics

### Current State
- Passing: 662/677 (97.8%)
- Failing: 15/677 (2.2%)

### Target State
- Passing: 677/677 (100%)
- Failing: 0/677 (0%)

### Milestones
- **Milestone 1**: Fix Phase 1 (Quick Wins) → 672/677 (99.3%)
- **Milestone 2**: Fix Phase 2 (Infrastructure) → 677/677 (100%)
- **Milestone 3**: Ship v2.0 with zero compromises

---

## File References

**Test Files** (READ-WRITE):
- `/Users/bmf/icode/mcpi/tests/test_functional_critical_workflows.py` (3 failures)
- `/Users/bmf/icode/mcpi/tests/test_functional_user_workflows.py` (3 failures)
- `/Users/bmf/icode/mcpi/tests/test_cli_scope_features.py` (2 failures)
- `/Users/bmf/icode/mcpi/tests/test_harness_example.py` (2 failures)
- `/Users/bmf/icode/mcpi/tests/test_installer.py` (1 failure)
- `/Users/bmf/icode/mcpi/tests/test_installer_workflows_integration.py` (1 failure)
- `/Users/bmf/icode/mcpi/tests/test_rescope_aggressive.py` (1 failure)
- `/Users/bmf/icode/mcpi/tests/test_tui_reload.py` (2 failures)

**Test Infrastructure** (READ-ONLY for reference):
- `/Users/bmf/icode/mcpi/tests/conftest.py` (fixtures)
- `/Users/bmf/icode/mcpi/tests/test_harness.py` (test harness)

**Production Code** (READ-ONLY - no changes needed):
- `/Users/bmf/icode/mcpi/src/mcpi/clients/file_based.py` (scope handlers)
- `/Users/bmf/icode/mcpi/src/mcpi/clients/types.py` (ServerConfig)
- `/Users/bmf/icode/mcpi/src/mcpi/tui/adapters/fzf.py` (TUI)

**Specifications** (READ-ONLY):
- `/Users/bmf/icode/mcpi/CLAUDE.md` - Project development guide
- `/Users/bmf/icode/mcpi/README.md` - User documentation

---

*Generated by: Backlog Planning Agent*
*Date: 2025-11-16 15:01:58*
*Source: STATUS-2025-11-16-145839.md*
*Total Work Items: 9 (covering all 15 test failures)*
*Total Effort: 4-6 hours to 100% pass rate*
